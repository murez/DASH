{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.integrate import simps\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_percentage(x): return int(x.split('%')[0])\n",
    "def remove_MiB(x): return int(x.split('MiB')[0])\n",
    "def remove_W(x): return float(x.split('W')[0])\n",
    "\n",
    "\n",
    "def convert_to_timestamp(x): return int(datetime.strptime(\n",
    "    x + \" +0800\", '%Y/%m/%d %H:%M:%S.%f %z').timestamp() * 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(name: str):\n",
    "    index_df = pl.read_csv(\n",
    "        \"index_nvidia_{}.txt\".format(name))\n",
    "    metrics_df = pl.read_csv(\"nvidiadata_{}.csv\".format(name))\n",
    "    metrics_df = metrics_df.with_columns([\n",
    "        pl.col('utilizationgpu').apply(remove_percentage),\n",
    "        pl.col('utilizationmemory').apply(remove_percentage),\n",
    "        pl.col('memoryfree').apply(remove_MiB),\n",
    "        pl.col('memoryused').apply(remove_MiB),\n",
    "        pl.col('powerdraw').apply(remove_W),\n",
    "        pl.col('timestamp').apply(convert_to_timestamp)\n",
    "    ])\n",
    "    metrics_df = metrics_df.drop('temperaturememory').drop(\n",
    "        'pcielinkgencurrent').drop('index')\n",
    "    data = []\n",
    "    for i in range(index_df.shape[0]):\n",
    "\n",
    "        model_name = index_df[i]['model'][0]\n",
    "        batch_size = index_df[i]['batch_size'][0]\n",
    "        start_time = index_df[i]['start_time'][0]\n",
    "        end_time = index_df[i]['end_time'][0]\n",
    "        duration = index_df[i]['duration'][0]\n",
    "\n",
    "        filted_data = metrics_df.filter(\n",
    "            pl.col('timestamp').is_between(\n",
    "                start_time / 1000000, end_time / 1000000)\n",
    "        ).to_numpy()[:, 1:]\n",
    "        \n",
    "        \n",
    "        if filted_data.shape[0] >= 1024:\n",
    "            length = 1024\n",
    "            filted_data = filted_data[:1024]\n",
    "\n",
    "        else:\n",
    "            length = filted_data.shape[0]\n",
    "            zero_padding = np.zeros((1024 - length, filted_data.shape[1]), dtype=np.float32)\n",
    "            filted_data = np.concatenate((filted_data, zero_padding), axis=0)\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                'model': model_name,\n",
    "                'batch_size': batch_size,\n",
    "                'duration': duration,\n",
    "                'data': filted_data,\n",
    "                'length': length\n",
    "            }\n",
    "        )\n",
    "        # data: \n",
    "        #       0 utilizationgpu,\n",
    "        #       1 utilizationmemory,\n",
    "        #       2 memoryfree,\n",
    "        #       3 memoryused,\n",
    "        #       4 temperaturegpu,\n",
    "        #       5 powerdraw\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transfer = []\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for x in ['A40', 'GTX_1080', 'RTX_2080', 'TITANX', 'TITANXp', 'V100']:\n",
    "    all_data[x] = process(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = {}\n",
    "\n",
    "for x in ['A40', 'GTX_1080', 'RTX_2080', 'TITANX', 'TITANXp', 'V100']:\n",
    "    data_label[x] = []\n",
    "    for d in all_data[x]:\n",
    "        i = 0\n",
    "        while d['model'] + '_' + str(i) in data_label[x]:\n",
    "            i += 1\n",
    "        data_label[x].append(\n",
    "            d['model'] + '_' + str(i)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['A40', 'GTX_1080', 'RTX_2080', 'TITANX', 'TITANXp', 'V100']:\n",
    "    for y in ['A40', 'GTX_1080', 'RTX_2080', 'TITANX', 'TITANXp', 'V100']:\n",
    "        for data_label_x in data_label[x]:\n",
    "            for data_label_y in data_label[y]:\n",
    "                if data_label_x.split('_')[0] == data_label_y.split('_')[0]:\n",
    "                    data_transfer.append(\n",
    "                        {\n",
    "                            'from': x,\n",
    "                            'to': y,\n",
    "                            'data_label': data_label_x.split('_')[0],\n",
    "                            'from_batch_size': all_data[x][data_label[x].index(data_label_x)]['batch_size'],\n",
    "                            'to_batch_size': all_data[y][data_label[y].index(data_label_y)]['batch_size'],\n",
    "                            'from_duration': all_data[x][data_label[x].index(data_label_x)]['duration'],\n",
    "                            'to_duration': all_data[y][data_label[y].index(data_label_y)]['duration'],\n",
    "                            'from_metrics': all_data[x][data_label[x].index(data_label_x)]['data'],\n",
    "                            'from_length': all_data[x][data_label[x].index(data_label_x)]['length']\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3021027"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 'A40',\n",
       " 'to': 'A40',\n",
       " 'data_label': 'hf',\n",
       " 'from_batch_size': 1,\n",
       " 'to_batch_size': 1,\n",
       " 'from_duration': 11576.40234375,\n",
       " 'to_duration': 11576.40234375,\n",
       " 'from_metrics': array([[1.0000e+02, 9.0000e+01, 4.0077e+04, 5.5570e+03, 3.2000e+01,\n",
       "         1.5479e+02],\n",
       "        [9.9000e+01, 9.1000e+01, 4.0077e+04, 5.5570e+03, 3.3000e+01,\n",
       "         1.6948e+02],\n",
       "        [9.9000e+01, 9.1000e+01, 4.0077e+04, 5.5570e+03, 3.3000e+01,\n",
       "         1.8035e+02],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]]),\n",
       " 'from_length': 110}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transfer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"transfer_data.npy\", data_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('sequence_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = set()\n",
    "for d in data:\n",
    "    if d['data'].shape[0] != 1024:\n",
    "        print(d['data'].shape[0], d['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnamelist = sorted(['timm_nfnet', 'resnet50_quantized_qat', 'shufflenet_v2_x1_0', 'densenet121', 'detectron2_maskrcnn', 'vgg16', 'hf_Bart', 'yolov3', 'hf_DistilBert', 'resnet18', 'hf_GPT2', 'hf_Albert', 'mobilenet_v3_large', 'maml_omniglot', 'timm_vision_transformer', 'maml', 'vision_maskrcnn', 'alexnet', 'nvidia_deeprecommender', 'LearningToPaint', 'resnext50_32x4d', 'hf_Bert', 'drq', 'timm_vovnet', 'pytorch_unet', 'hf_T5', 'mobilenet_v2', 'timm_regnet', 'squeezenet1_1', 'pytorch_CycleGAN_and_pix2pix', 'hf_Reformer', 'dcgan', 'Super_SloMo', 'mobilenet_v2_quantized_qat', 'hf_Longformer', 'resnet50', 'timm_efficientnet', 'attention_is_all_you_need_pytorch', 'BERT_pytorch', 'mnasnet1_0', 'fastNLP_Bert', 'hf_BigBird'])\n",
    "model_name_to_num = {modelnamelist.index(model): model for model in modelnamelist}\n",
    "model_num_to_name = {model: modelnamelist.index(model) for model in modelnamelist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'batch_size', 'duration', 'data', 'length'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShanghaitechData\n",
    "\n",
    "ds = ShanghaitechData.ShanghaitechClusterDataset('/home/murez/CS225/project/throughput_estimator/Shanghaitech_SIST_datacenter/transfer_data.npy')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dl:\n",
    "    (device_feature,\n",
    "    from_metrics, \n",
    "    from_length,\n",
    "    duration_rate) = d\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DashEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murez/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "m = DashEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-55.9812],\n",
       "        [-77.7703],\n",
       "        [-78.9193],\n",
       "        [-76.9743],\n",
       "        [-60.4700],\n",
       "        [-79.2917],\n",
       "        [-54.5944],\n",
       "        [-76.1798],\n",
       "        [-79.6758],\n",
       "        [-77.6575],\n",
       "        [-56.8798],\n",
       "        [-71.5048],\n",
       "        [-63.9357],\n",
       "        [-76.7603],\n",
       "        [-81.4734],\n",
       "        [-61.4035],\n",
       "        [-52.9177],\n",
       "        [-54.5732],\n",
       "        [-80.5189],\n",
       "        [-78.7876],\n",
       "        [-71.6160],\n",
       "        [-79.4317],\n",
       "        [-65.1680],\n",
       "        [-80.1811],\n",
       "        [-78.8246],\n",
       "        [-79.2175],\n",
       "        [-79.4171],\n",
       "        [-78.8692],\n",
       "        [-77.1077],\n",
       "        [-64.1454],\n",
       "        [-52.4029],\n",
       "        [-64.2431],\n",
       "        [-77.8095],\n",
       "        [-55.4689],\n",
       "        [-81.0892],\n",
       "        [-71.7560],\n",
       "        [-52.6316],\n",
       "        [-71.7816],\n",
       "        [-78.3162],\n",
       "        [-52.3811],\n",
       "        [-81.7865],\n",
       "        [-60.4838],\n",
       "        [-55.1627],\n",
       "        [-78.4862],\n",
       "        [-78.8800],\n",
       "        [-77.5968],\n",
       "        [-71.2326],\n",
       "        [-66.3137],\n",
       "        [-76.8101],\n",
       "        [-77.0593],\n",
       "        [-76.8578],\n",
       "        [-63.4617],\n",
       "        [-70.9655],\n",
       "        [-77.4177],\n",
       "        [-78.0656],\n",
       "        [-78.0475],\n",
       "        [-78.1730],\n",
       "        [-63.8058],\n",
       "        [-79.3072],\n",
       "        [-63.8428],\n",
       "        [-76.7603],\n",
       "        [-76.6874],\n",
       "        [-62.7303],\n",
       "        [-65.2663]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(device_feature, from_metrics, from_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "device_from = 'A40'\n",
    "device_to = ['A40', 'GTX_1080', 'RTX_2080', 'TITANX', 'TITANXp', 'V100']\n",
    "from_batch_size = 64\n",
    "to_batch_size = [16, 32, 256, 64, 64, 64]\n",
    "\n",
    "transfer_feature = []\n",
    "for i, to in enumerate(device_to):\n",
    "    from_device_config = GPU_config_list[device_from]\n",
    "    to_device_config = GPU_config_list[to]\n",
    "    feature = np.concatenate([from_device_config, to_device_config, from_batch_size, to_batch_size[i]], axis=None)\n",
    "    transfer_feature.append(feature)\n",
    "transfer_feature = torch.from_numpy(np.array(transfer_feature)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([from_metrics[0].unsqueeze(0) for x in range(10)], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302102"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(ds) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x7fe0d8630040>,\n",
       " <torch.utils.data.dataset.Subset at 0x7fe0d86300a0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.inf > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murez/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/332 [00:00<?, ?it/s]/home/murez/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([8192])) that is different to the input size (torch.Size([8192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|█████████▉| 331/332 [05:41<00:01,  1.30s/it]/home/murez/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([7373])) that is different to the input size (torch.Size([7373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 332/332 [05:42<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 46.7809\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [06:09<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 45.3443\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [05:39<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 | train loss: 30.3647\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [05:23<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 | train loss: 58.1206\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [05:32<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 | train loss: 28.6978\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 305/332 [04:35<00:27,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "import predictor\n",
    "predict = predictor.DashPredictor()\n",
    "predict.train(8192)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec92373eb85d7e85c22f55db683c083854f1ea57bbead13cebfc370924f2b270"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
